{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MSIS579_LAB_Lesson1_XOR_Worksheet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mialdrid/Python/blob/master/MSIS579_LAB_Lesson1_XOR_Worksheet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "D3QlsEiYR057",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network for logical XOR Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "o_ghiy3uR059",
        "colab_type": "text"
      },
      "source": [
        "In this lesson you will build a small neural network in Keras and train it to replicate the logical XOR function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "cwhArhP_R05-",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "VmFTtgahR05_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7ec5d764-72f8-4b2b-83e7-09415a9630a1"
      },
      "source": [
        "%tensorflow_version 1.14\n",
        "%matplotlib inline\n",
        "from IPython.display import SVG\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense\n",
        "from keras.regularizers import l2\n",
        "from keras.utils.vis_utils import model_to_dot"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.14`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "XAhW-JccR06G",
        "colab_type": "text"
      },
      "source": [
        "## Create dataset for the logical XOR function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "tI_AE4FnR06H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_X = np.array([[0, 0],\n",
        "                   [1, 0],\n",
        "                   [0, 1],\n",
        "                   [1, 1]])\n",
        "data_y = np.array([0, \n",
        "                   1, \n",
        "                   1, \n",
        "                   0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "Ur8-OukhR06K",
        "colab_type": "text"
      },
      "source": [
        "## Build the neural net model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "9-oc8QZ1R06L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6d86e384-c5e8-4481-93a7-7a21d079a331"
      },
      "source": [
        "# TODO\n",
        "#Build a single layer nueral network\n",
        "# the input shape is 2 because we have x1 and x2\n",
        "# the function is sigmoid because the output is binary its 0 or 1\n",
        "model = Sequential()\n",
        "model.add(Dense(2, input_shape=(2,), activation='sigmoid'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "YA3nc0wsR06Q",
        "colab_type": "code",
        "outputId": "441d67d6-1646-48d7-e508-27614c1b1f73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 2)                 6         \n",
            "=================================================================\n",
            "Total params: 6\n",
            "Trainable params: 6\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "bnmBwvq9R06W",
        "colab_type": "text"
      },
      "source": [
        "# Question 1: \n",
        "How many parameters are there in the model so far? Why? Explain in detail what each parameter represents. Answer in the cell below. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLKV0_3xR06X",
        "colab_type": "text"
      },
      "source": [
        "6 parameters. There are 2 input nodes, connected to 2 hidden nodes. This gives 2x2 = 4 weights. This accounts for 4 of the parameters.\n",
        "\n",
        "The other 2 parameters are the bias terms: one bias weight for each of the two hidden nodes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "e3-CNzAjR06Y",
        "colab_type": "text"
      },
      "source": [
        "## Add another layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "S5l_yKf6R06Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO\n",
        "# we dont need to define the input shape again because we are just adding a layer\n",
        "# units =1 because we are outputing a binary value 0 or 1\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "mwCj-5F5R06c",
        "colab_type": "code",
        "outputId": "e7609caf-2bf5-4a36-e02f-0fc9ab48eab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 2)                 6         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "hvJYpNGuR06h",
        "colab_type": "text"
      },
      "source": [
        "## Question 2: \n",
        "How many new parameters are there now (e.g., how many were added after question 1)? Why? What does each new parameter represent? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpFyyzUcR06i",
        "colab_type": "text"
      },
      "source": [
        "There are 3 new parameters (for a total of 9). The new layer contains a single node, so each of the 2 previous hidden-layer nodes are connected to this single new node. That gives 2 regular weights. In addition, the new single node has a single bias node, connected to it with 1 weight. Hence there are 3 new weights in the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "z6VqwNQ2R06k",
        "colab_type": "text"
      },
      "source": [
        "## Visualize the model\n",
        "#Ignore this for now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "R2HcVRKvR06m",
        "colab_type": "code",
        "outputId": "fdf44594-efdd-458f-9041-6badc61ca651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "SVG(model_to_dot(model, show_shapes=True, dpi=65).create(prog='dot', format='svg'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"200pt\" viewBox=\"0.00 0.00 311.00 221.00\" width=\"281pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(.9028 .9028) rotate(0) translate(4 217)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-217 307,-217 307,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139839569471976 -->\n<g class=\"node\" id=\"node1\">\n<title>139839569471976</title>\n<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 303,-212.5 303,-166.5 0,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-185.8\">dense_1_input: InputLayer</text>\n<polyline fill=\"none\" points=\"173,-166.5 173,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"173,-189.5 231,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"231,-166.5 231,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-197.3\">(None, 2)</text>\n<polyline fill=\"none\" points=\"231,-189.5 303,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-174.3\">(None, 2)</text>\n</g>\n<!-- 139839569470744 -->\n<g class=\"node\" id=\"node2\">\n<title>139839569470744</title>\n<polygon fill=\"none\" points=\"33,-83.5 33,-129.5 270,-129.5 270,-83.5 33,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-102.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"140,-83.5 140,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"140,-106.5 198,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"198,-83.5 198,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"234\" y=\"-114.3\">(None, 2)</text>\n<polyline fill=\"none\" points=\"198,-106.5 270,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"234\" y=\"-91.3\">(None, 2)</text>\n</g>\n<!-- 139839569471976&#45;&gt;139839569470744 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139839569471976-&gt;139839569470744</title>\n<path d=\"M151.5,-166.3799C151.5,-158.1745 151.5,-148.7679 151.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"155.0001,-139.784 151.5,-129.784 148.0001,-139.784 155.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139839569366880 -->\n<g class=\"node\" id=\"node3\">\n<title>139839569366880</title>\n<polygon fill=\"none\" points=\"33,-.5 33,-46.5 270,-46.5 270,-.5 33,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-19.8\">dense_2: Dense</text>\n<polyline fill=\"none\" points=\"140,-.5 140,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"140,-23.5 198,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"198,-.5 198,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"234\" y=\"-31.3\">(None, 2)</text>\n<polyline fill=\"none\" points=\"198,-23.5 270,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"234\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 139839569470744&#45;&gt;139839569366880 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139839569470744-&gt;139839569366880</title>\n<path d=\"M151.5,-83.3799C151.5,-75.1745 151.5,-65.7679 151.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"155.0001,-56.784 151.5,-46.784 148.0001,-56.784 155.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "FJcntixsR06r",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "6DPMHm__R06r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the model using adam as the optmizer and binary_crossentropy as the loss. \n",
        "# checkout compile API: https://keras.io/models/sequential/#compile\n",
        "\n",
        "# TODO\n",
        "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "3voJQXlpR06w",
        "colab_type": "text"
      },
      "source": [
        "### Modify the steps per epoch, number of epochs, etc. below as needed. The goal should be 100% accuracy for the XOR data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX8PQhoOR06x",
        "colab_type": "code",
        "outputId": "bfd6d753-8993-4838-c605-bb5acf77700c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "# fit the model using 500 steps per epoch and 10 epochs\n",
        "# checkout fit API: https://keras.io/models/sequential/#fit\n",
        "\n",
        "# TODO\n",
        "#steps_per_epoch defines how many data points we want to look at for each epoch.\n",
        "# if this is not specificed each epoch will go through the entire dataset\n",
        "# this allows us to update the model parameters quickly, but looking at a certain set of parameters\n",
        "model.fit(data_X, data_y, steps_per_epoch=500, epochs=20)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.0154 - acc: 1.0000\n",
            "Epoch 2/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.0153 - acc: 1.0000\n",
            "Epoch 3/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.0152 - acc: 1.0000\n",
            "Epoch 4/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.0150 - acc: 1.0000\n",
            "Epoch 5/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.0149 - acc: 1.0000\n",
            "Epoch 6/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.0148 - acc: 1.0000\n",
            "Epoch 7/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.0147 - acc: 1.0000\n",
            "Epoch 8/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.0146 - acc: 1.0000\n",
            "Epoch 9/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.0145 - acc: 1.0000\n",
            "Epoch 10/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.0144 - acc: 1.0000\n",
            "Epoch 11/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.0143 - acc: 1.0000\n",
            "Epoch 12/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.0142 - acc: 1.0000\n",
            "Epoch 13/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.0141 - acc: 1.0000\n",
            "Epoch 14/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.0140 - acc: 1.0000\n",
            "Epoch 15/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.0139 - acc: 1.0000\n",
            "Epoch 16/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.0138 - acc: 1.0000\n",
            "Epoch 17/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.0137 - acc: 1.0000\n",
            "Epoch 18/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.0136 - acc: 1.0000\n",
            "Epoch 19/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.0135 - acc: 1.0000\n",
            "Epoch 20/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.0134 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2ead6166a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "UTEsca_2R063",
        "colab_type": "text"
      },
      "source": [
        "### Run the trained model on the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "pkQEQfisR064",
        "colab_type": "code",
        "outputId": "bd89d1ab-0fc3-4bae-fb47-6998acd26fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# make predictions on the data fed into the model.\n",
        "# checkout predict API: https://keras.io/models/sequential/#predict\n",
        "\n",
        "# TODO\n",
        "model.predict(data_X)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01059984],\n",
              "       [0.9880337 ],\n",
              "       [0.98802817],\n",
              "       [0.01859375]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "_uWEq9owR069",
        "colab_type": "text"
      },
      "source": [
        "# Question 3:\n",
        "Explain the results of the predict() call above. How well did the trained model do on this problem?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-GgvoVYR06-",
        "colab_type": "text"
      },
      "source": [
        "The model is close to the desire results given in data_y (see following cell). The results are not exact because we have a sigmoid activation and will never output exactly 1 or 0. But if we consider a threshold of 0.5, setting the output to 1 if above threshold and 0 otherwise, then indeed the output is exactly [0,1,1,0] for the 4 inputs, as expected. Thus the network has solved the XOR problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tfCKNMCR07A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09a31f46-41c1-49ba-b843-701e3a16cc2d"
      },
      "source": [
        "data_y"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "bo1huq3fR07J",
        "colab_type": "text"
      },
      "source": [
        "# Question 4:\n",
        "Print the weights of both layers of the trained network below. HINT: model.layers gives a list of layers. layer.get_weights() returns layer weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZY-JNqVR07K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3a21d45f-c67f-46d5-ca6f-4242db08ec55"
      },
      "source": [
        "# print the weights of the first layer \n",
        "# TODO\n",
        "model.layers[0].get_weights()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-4.9550266, -6.524761 ],\n",
              "        [-4.95423  , -6.5197697]], dtype=float32),\n",
              " array([7.366573 , 2.6723456], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QMMDvL-R07Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "17dca578-047f-491f-942e-f4fa5e5471f5"
      },
      "source": [
        "# print the weights of the second layer \n",
        "# TODO\n",
        "model.layers[1].get_weights()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 10.182215],\n",
              "        [-10.694892]], dtype=float32), array([-4.7083087], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}